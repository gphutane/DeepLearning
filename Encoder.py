# -*- coding: utf-8 -*-
"""encoder(gauri)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qhQnn0oJLjGcDV4UzofxOS99Wn82r5qY
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix,classification_report
import tensorflow as tf
from keras.layers import Dense,BatchNormalization,MaxPooling2D,Conv2D,Dropout,Flatten
from keras.models import Model,Sequential
from keras.optimizers import SGD

df=pd.read_csv('/content/ecg_autoencoder_dataset.csv')
df

df.shape

X=df.drop('1',axis=1)
X

y=df['1']
y

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)

scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

encoder=Sequential([Dense(64,activation='relu',input_shape = (X_train.shape[1],))])
decoder=Sequential([Dense(X_train.shape[1],activation='sigmoid')])

autoencoder=Sequential([encoder,decoder])

autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

r=autoencoder.fit(X_train,y_train,epochs=50,batch_size=64,validation_data=(X_test,X_test))

r.history.keys()

import matplotlib.pyplot as plt
plt.plot(r.history['loss'],label='loss',color='blue')
plt.plot(r.history['val_loss'],label='val_loss',color='red')
plt.legend
plt.xlabel('epoch')
plt.ylabel('loss')

plt.plot(r.history['accuracy'],label='loss',color='blue')
plt.plot(r.history['val_accuracy'],label='val_loss',color='red')
plt.legend

loss= autoencoder.evaluate(X_test, X_test)
# Evaluate the model on the test set
decoded_data = autoencoder.predict(X_test)
mse = np.mean(np.power(X_test - decoded_data, 2), axis=1)
threshold = np.percentile(mse, 95)  # Adjust the percentile as needed for tuning sensitivity

# Identify outliers based on the threshold
outliers = mse > threshold

# Print evaluation metrics for anomaly detection
print("Confusion Matrix:\n", confusion_matrix(y_test, outliers))
print("\nClassification Report:\n", classification_report(y_test, outliers))

# Print the number of outliers and anomalies
num_outliers = np.sum(outliers)
num_anomalies = np.sum(y_test[outliers] == 1)  # Assuming 1 represents the positive class

print(f'Number of outliers: {num_outliers}')
print(f'Number of anomalies: {num_anomalies}')

